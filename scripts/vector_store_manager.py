# scripts/vector_store_manager.py
import json
import chromadb
from chromadb.config import Settings
import numpy as np
import os
import sys

class SimpleVectorStore:
    def __init__(self, persist_directory="./chroma_db"):
        """Khá»Ÿi táº¡o vector store Ä‘Æ¡n giáº£n"""
        self.persist_directory = persist_directory
        os.makedirs(persist_directory, exist_ok=True)
        
        # Khá»Ÿi táº¡o ChromaDB client
        self.client = chromadb.PersistentClient(path=persist_directory)
        print("âœ… ÄÃ£ khá»Ÿi táº¡o ChromaDB client")
    
    def create_simple_embeddings(self, texts):
        """Táº¡o embeddings Ä‘Æ¡n giáº£n (placeholder - sáº½ thay báº±ng model tháº­t sau)"""
        print("ğŸ”§ Äang táº¡o embeddings...")
        embeddings = []
        
        for text in texts:
            # Táº¡o vector giáº£ Ä‘á»‹nh cÃ³ 384 dimensions (giá»‘ng sentence-transformers)
            words = text.split()
            vector = np.random.randn(384).tolist()  # Vector ngáº«u nhiÃªn táº¡m thá»i
            embeddings.append(vector)
        
        return embeddings
    
    def create_collection(self, collection_name="company_documents"):
        """Táº¡o collection trong ChromaDB"""
        try:
            # Thá»­ láº¥y collection náº¿u Ä‘Ã£ tá»“n táº¡i
            collection = self.client.get_collection(collection_name)
            print(f"âœ… Collection '{collection_name}' Ä‘Ã£ tá»“n táº¡i")
            return collection
        except Exception as e:
            # Táº¡o collection má»›i
            collection = self.client.create_collection(
                name=collection_name,
                metadata={"hnsw:space": "cosine"}  # Sá»­ dá»¥ng cosine similarity
            )
            print(f"âœ… ÄÃ£ táº¡o collection má»›i: '{collection_name}'")
            return collection
    
    def add_documents_to_collection(self, collection, chunks):
        """ThÃªm documents vÃ o vector database"""
        print("ğŸ“¥ Äang thÃªm documents vÃ o vector database...")
        
        documents = []
        metadatas = []
        ids = []
        
        for chunk in chunks:
            documents.append(chunk['content'])
            metadatas.append({
                "document_id": chunk['document_id'],
                "category": chunk['category'],
                "allowed_roles": json.dumps(chunk['allowed_roles']),  # LÆ°u dáº¡ng JSON string
                "title": chunk['title'],
                "chunk_index": chunk['chunk_index'],
                "total_chunks": chunk['total_chunks'],
                "word_count": chunk['word_count']
            })
            ids.append(chunk['id'])
        
        # Táº¡o embeddings Ä‘Æ¡n giáº£n
        embeddings = self.create_simple_embeddings(documents)
        
        # ThÃªm vÃ o collection
        collection.add(
            embeddings=embeddings,
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        
        print(f"âœ… ÄÃ£ thÃªm {len(documents)} documents vÃ o collection")
        
        # Thá»‘ng kÃª
        categories = {}
        for chunk in chunks:
            cat = chunk['category']
            categories[cat] = categories.get(cat, 0) + 1
        
        print(f"ğŸ“Š PhÃ¢n bá»‘ theo category:")
        for cat, count in categories.items():
            print(f"   â€¢ {cat}: {count} chunks")
    
    def test_search(self, collection, query_text="nghá»‰ phÃ©p", n_results=3):
        """Test tÃ¬m kiáº¿m trong vector database"""
        print(f"\nğŸ” TEST TÃŒM KIáº¾M: '{query_text}'")
        
        # Táº¡o embedding cho query
        query_embedding = self.create_simple_embeddings([query_text])[0]
        
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results
        )
        
        print(f"âœ… TÃ¬m tháº¥y {len(results['documents'][0])} káº¿t quáº£:")
        
        for i, (doc, metadata, distance) in enumerate(zip(
            results['documents'][0], 
            results['metadatas'][0], 
            results['distances'][0]
        )):
            print(f"\n--- Káº¿t quáº£ {i+1} (distance: {distance:.4f}) ---")
            print(f"Title: {metadata['title']}")
            print(f"Category: {metadata['category']}")
            print(f"Content: {doc[:100]}...")

def main():
    # Khá»Ÿi táº¡o vector store
    print("ğŸš€ Báº®T Äáº¦U THIáº¾T Láº¬P VECTOR DATABASE")
    print("=" * 50)
    
    vector_store = SimpleVectorStore()
    
    # Táº¡o collection
    collection = vector_store.create_collection()
    
    # Load chunks tá»« bÆ°á»›c trÆ°á»›c
    try:
        with open('outputs/document_chunks.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        chunks = data['chunks']
        print(f"ğŸ“– ÄÃ£ load {len(chunks)} chunks tá»« file")
        
        # ThÃªm documents vÃ o collection
        vector_store.add_documents_to_collection(collection, chunks)
        
        # Test search
        vector_store.test_search(collection, "nghá»‰ phÃ©p")
        vector_store.test_search(collection, "lÆ°Æ¡ng thÆ°á»Ÿng")
        vector_store.test_search(collection, "giá» lÃ m viá»‡c")
        
        print(f"\nğŸ‰ HOÃ€N THÃ€NH THIáº¾T Láº¬P VECTOR DATABASE")
        print(f"ğŸ“ Database location: ./chroma_db")
        
    except FileNotFoundError:
        print("âŒ File outputs/document_chunks.json khÃ´ng tá»“n táº¡i")
        print("   HÃ£y cháº¡y BÆ°á»›c 1.2 trÆ°á»›c")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()