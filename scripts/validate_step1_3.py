# scripts/validate_step1_3.py
import os
import json
import sys
import pickle
# import numpy as np

def validate_step1_3():
    print("üîç KI·ªÇM TRA HO√ÄN TH√ÄNH B∆Ø·ªöC 1.3")
    print("=" * 50)
    
    # Ki·ªÉm tra th∆∞ m·ª•c simple_vector_store
    print("1. Ki·ªÉm tra vector database:")
    db_path = './simple_vector_store'
    db_file = f'{db_path}/vector_store.pkl'
    
    if os.path.exists(db_file):
        print(f"   ‚úÖ File database: {db_file}")
        
        # Ki·ªÉm tra k√≠ch th∆∞·ªõc file
        file_size = os.path.getsize(db_file)
        print(f"   ‚Ä¢ K√≠ch th∆∞·ªõc file: {file_size} bytes")
    else:
        print(f"   ‚ùå File database kh√¥ng t·ªìn t·∫°i: {db_file}")
        return False
    
    # Ki·ªÉm tra n·ªôi dung vector store
    print("\n2. Ki·ªÉm tra n·ªôi dung vector store:")
    try:
        with open(db_file, 'rb') as f:
            data = pickle.load(f)
        
        vectors = data.get('vectors', {})
        metadata = data.get('metadata', {})
        
        print(f"   ‚úÖ ƒê·ªçc file th√†nh c√¥ng")
        print(f"   ‚Ä¢ S·ªë vectors: {len(vectors)}")
        print(f"   ‚Ä¢ S·ªë metadata: {len(metadata)}")
        
        # Ki·ªÉm tra vector dimensions
        if vectors:
            sample_vector = list(vectors.values())[0]
            print(f"   ‚Ä¢ Vector dimensions: {len(sample_vector)}")
        
    except Exception as e:
        print(f"   ‚ùå L·ªói ƒë·ªçc file: {e}")
        return False
    
    # Ki·ªÉm tra metadata
    print("\n3. Ki·ªÉm tra metadata:")
    try:
        if metadata:
            sample_metadata = list(metadata.values())[0]
            required_fields = ['document_id', 'category', 'allowed_roles', 'title']
            missing_fields = [field for field in required_fields if field not in sample_metadata]
            
            if not missing_fields:
                print(f"   ‚úÖ Metadata ƒë·∫ßy ƒë·ªß")
                print(f"   ‚Ä¢ Category: {sample_metadata.get('category')}")
                print(f"   ‚Ä¢ Title: {sample_metadata.get('title')}")
                print(f"   ‚Ä¢ Roles: {sample_metadata.get('allowed_roles')}")
            else:
                print(f"   ‚ùå Thi·∫øu fields: {missing_fields}")
                return False
    except Exception as e:
        print(f"   ‚ùå L·ªói ki·ªÉm tra metadata: {e}")
        return False
    
    # Test search functionality
    print("\n4. Ki·ªÉm tra ch·ª©c nƒÉng t√¨m ki·∫øm:")
    try:
        # T·∫°o class test ƒë∆°n gi·∫£n
        class TestVectorStore:
            def __init__(self, vectors, metadata):
                self.vectors = vectors
                self.metadata = metadata
            
            def cosine_similarity(self, vec1, vec2):
                dot_product = np.dot(vec1, vec2)
                norm1 = np.linalg.norm(vec1)
                norm2 = np.linalg.norm(vec2)
                if norm1 == 0 or norm2 == 0:
                    return 0
                return dot_product / (norm1 * norm2)
            
            def test_search(self, query_vector):
                similarities = []
                for chunk_id, vector in self.vectors.items():
                    similarity = self.cosine_similarity(query_vector, vector)
                    similarities.append((chunk_id, similarity))
                
                similarities.sort(key=lambda x: x[1], reverse=True)
                return similarities[:2]  # Tr·∫£ v·ªÅ 2 k·∫øt qu·∫£
        
        # Test search
        test_store = TestVectorStore(vectors, metadata)
        if vectors:
            test_vector = list(vectors.values())[0]  # D√πng vector ƒë·∫ßu ti√™n ƒë·ªÉ test
            results = test_store.test_search(test_vector)
            
            if results:
                print(f"   ‚úÖ Search ho·∫°t ƒë·ªông")
                print(f"   ‚Ä¢ Tr·∫£ v·ªÅ: {len(results)} k·∫øt qu·∫£")
                print(f"   ‚Ä¢ Similarity range: {results[0][1]:.4f} - {results[-1][1]:.4f}")
            else:
                print(f"   ‚ö†Ô∏è  Search tr·∫£ v·ªÅ 0 k·∫øt qu·∫£")
                
    except Exception as e:
        print(f"   ‚ùå L·ªói search test: {e}")
        return False
    
    # Ki·ªÉm tra file chunks g·ªëc
    print("\n5. Ki·ªÉm tra file chunks g·ªëc:")
    chunks_file = "outputs/document_chunks.json"
    if os.path.exists(chunks_file):
        with open(chunks_file, 'r', encoding='utf-8') as f:
            chunks_data = json.load(f)
        chunks_count = len(chunks_data['chunks'])
        print(f"   ‚úÖ File chunks g·ªëc: {chunks_count} chunks")
        
        # So s√°nh s·ªë l∆∞·ª£ng
        if chunks_count == len(vectors):
            print(f"   ‚úÖ S·ªë l∆∞·ª£ng kh·ªõp: {chunks_count} chunks = {len(vectors)} vectors")
        else:
            print(f"   ‚ö†Ô∏è  S·ªë l∆∞·ª£ng kh√¥ng kh·ªõp: {chunks_count} chunks vs {len(vectors)} vectors")
    else:
        print(f"   ‚ùå File chunks kh√¥ng t·ªìn t·∫°i")
        return False
    
    # T·ªïng k·∫øt
    print("\n" + "=" * 50)
    print("üéâ HO√ÄN TH√ÄNH B∆Ø·ªöC 1.3 - VECTOR STORE TH√ÄNH C√îNG")
    print(f"\nüìä TH·ªêNG K√ä:")
    print(f"   ‚Ä¢ Database location: {db_path}")
    print(f"   ‚Ä¢ Total vectors: {len(vectors)}")
    print(f"   ‚Ä¢ Vector dimensions: {len(list(vectors.values())[0]) if vectors else 0}")
    print(f"   ‚Ä¢ Search: Ho·∫°t ƒë·ªông")
    print(f"   ‚Ä¢ File chunks: {chunks_count} chunks")
    
    return True

if __name__ == "__main__":
    success = validate_step1_3()
    sys.exit(0 if success else 1)